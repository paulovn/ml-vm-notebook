{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Pandas DataFrame operations\n",
    "\n",
    "A few first steps with [Pandas](http://pandas.pydata.org/pandas-docs/stable/).\n",
    "\n",
    "We'll create a small dataframe, access its elements, and enlarge it by adding new columns and rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "\n",
    "# Import Pandas & NumPy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tiny dataset, as a list of tuples\n",
    "name = ('Oslo','Copenhaguen','Helsinki','Stockholm','Reykjavik')\n",
    "pop = ( 647676, 583348, 626305, 917297, 121822 )\n",
    "area = ( 480.76, 86.20, 715.49, 188.0,  273 )\n",
    "data = [ (1000+i,n,p,s) for i, (n,p,s) in enumerate(zip(name,pop,area)) ]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Creating a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe from the list of tuples. We need to add the names of the columns, plus\n",
    "# the column(s) we want to be used as row index\n",
    "df = pd.DataFrame.from_records( data=data, columns=('id','name','population','area'), index=['id'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the dataframe. We can print it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the options we've got for data formatting\n",
    "pd.describe_option('display')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can just show it, and it will be nicely formatted.\n",
    "Note the double header: the second header row is for the column(s) forming the DataFrame index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe dimensions\n",
    "print(df.shape)\n",
    "# Check dataframe components\n",
    "print(df.index)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Fetching columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or also\n",
    "df.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get more than one column. \n",
    "These operations create and return a new DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ ['name','population'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing, but this time we get a reference to the original DataFrame by using a *locator* operator (see [next section](#3-Accessing-DataFrame-contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['name','population']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Accessing DataFrame contents\n",
    "There are [several ways](http://pandas.pydata.org/pandas-docs/stable/indexing.html#different-choices-for-indexing)  of accessing the elements contained in a DataFrame\n",
    "\n",
    "### 3.1 By label\n",
    "\n",
    "We can acccess rows and columns by [using labels](http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-label), i.e. the index for the rows and/or columns, using the `loc` locator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One row, using the index. Note that in this case our row index is the 'id' column\n",
    "df.loc[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two rows\n",
    "df.loc[1002:1003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two rows, but only selected columns\n",
    "df.loc[1002:1003,'name':'population']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 By position\n",
    "\n",
    "And we can also select row/columns by [their position ](http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-integer) using the `iloc` locator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first row\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last row\n",
    "df.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 By boolean selection\n",
    "Another possibility is to use a logical expression to create a boolean matrix, and index with it, selecting the rows that satisfy the expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.area<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ (df.area<200) & (df.population>600000) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variant returns the same size as the original dataframe, but fills only the rows that satisty the condition\n",
    "df.where( df.area<200 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Augmenting a DataFrame\n",
    "Let's take the existing dataframe and enlarge it by adding new rows/columns\n",
    "\n",
    "### 4.1 Adding a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new column by combining data from other columns\n",
    "df.loc[:,'density'] = df.loc[:,'population']/df.loc[:,'area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of doing it is to use the [`assign()`](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#assigning-new-columns-in-method-chains) method. Ir returns a new DataFrame with the additions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.assign( density2 = lambda x : x.population/x.area )\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Adding rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the next id to insert\n",
    "next = df.tail(1).index.values[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new rows. This time, for a change, we'll be using a dict of lists as input data\n",
    "name = ('Tallinn', 'Riga', 'Vilnius')\n",
    "pop = ( 439286, 641007, 542664 )\n",
    "size = ( 159.2, 304, 401 )\n",
    "data2 = { 'id' : range(next,next+len(name)),\n",
    "          'name' : name, \n",
    "          'population' : pop, \n",
    "          'area' : size  }\n",
    "#data = [ {'id':next+i, 'name':n, 'population': p, size:'s' } \n",
    "#         for i, (n,p,s) in enumerate(zip(name,pop,size)) ]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the dict of lists\n",
    "df2 = pd.DataFrame( data2 )\n",
    "# Set the column(s) to be used as the row index in this new dataframe\n",
    "df2.set_index( 'id', inplace=True )\n",
    "#df2 = pd.DataFrame.from_dict( data )\n",
    "#df.append( data, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now append this set of rows to the original one\n",
    "df = df.append(df2, sort=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the rows having a missing density value. Obviously they will be the just added ones\n",
    "missing = df[ np.isnan(df.density) ].index\n",
    "\n",
    "df.loc[missing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the missing densities. First naive attempt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[missing].density = df.loc[missing].population/df.loc[missing].area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[missing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It didn't work. Why? Because we are selecting in two steps:\n",
    "* first we get the rows `df.loc[missing]`\n",
    "* and then we get the column of those rows `df.loc[missing].population`\n",
    "This is [chained indexing](http://pandas.pydata.org/pandas-docs/stable/indexing.html#returning-a-view-versus-a-copy). And [it fails](http://pandas.pydata.org/pandas-docs/stable/indexing.html#why-does-assignment-fail-when-using-chained-indexing) when using it for assignment\n",
    "\n",
    "So let's try again, using a single-step indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[missing,'density'] = df.loc[missing,'population']/df.loc[missing,'area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[missing].density"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
